{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quora_Dataset_Seq2seq_Model.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnarevi/TSAI_END2.0_Session7/blob/main/Quora_Dataset_Seq2seq_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN9WseVUlmEz"
      },
      "source": [
        "# Neural Machine Translation with Quora Question Pairs Dataset \n",
        "Here we will be building a sequence to sequence deep learning model using PyTorch and TorchText for prediction of duplicate questions .Sequence to Sequence (seq2seq) model here uses an encoder-decoder architecture. Encoder neural network encodes the input sequence(question1) into a single vector, also called as a Context Vector,which is an abstract representation of the input sequence.This vector is then passed into the decoder neural network, which is used to output the corresponding output sequence (duplicate), one word at a time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpQgJ7dAlpoQ"
      },
      "source": [
        "##  Preparing Data\n",
        "Import all the required modules and  set the random seeds for deterministic results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d27S03zbAAPu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import torch, torchtext\n",
        "from torchtext import legacy\n",
        "from torchtext.legacy import data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zShL1b6zl3LC"
      },
      "source": [
        "\n",
        "Mount drive to access dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7l29xRJWqhf",
        "outputId": "a4566500-4462-4083-daa0-27d41488d500"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQSoI0keXGLf"
      },
      "source": [
        "path='/content/drive/MyDrive/TSAI_data/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSQEcla0Ad0E"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "# !pip install spacy --upgrade\n",
        "# import dependencies\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCdbS6Zzl5XZ"
      },
      "source": [
        "## Dataset\n",
        "We will be using first public dataset of Quora released in january 2017 .The Quora dataset consists of a large number of question pairs and a label which mentions whether the question pair is logically duplicate or not. For example, two questions below carry the same intent.\n",
        "\n",
        "*“What is the most populous state in the USA?”*\n",
        "\n",
        "*“Which state in the United States has the most people?”* \n",
        "\n",
        "Ideally, only one of the two should be present on Quora.\n",
        "\n",
        "The data set consisted of around 400,000 pairs of questions organized in the form of 6 columns as explained -\n",
        "\n",
        "\n",
        "*   id: Row ID\n",
        "*   qid 1, qid 2: The unique ID of each question in the pair\n",
        "*  question 1, question 2: The actual textual contents of the questions.\n",
        "*  is_duplicate: Label is 0 for questions which are semantically different and 1 for questions which essentially would have only one answer (duplicate questions)\n",
        "\n",
        "63% of the questions pairs are semantically non-similar and 37% are duplicate questions pairs.We will consider only questions with duplicates for our modeling\n",
        "\n",
        "Let's view first few lines of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Qh5Azc50XigI",
        "outputId": "3375c847-298a-482d-a551-07c55e92a05b"
      },
      "source": [
        "df=pd.read_csv(path+\"quora_duplicate_questions.tsv\",sep='\\t')\n",
        "df= df.iloc[:,3:]\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  ... is_duplicate\n",
              "0  What is the step by step guide to invest in sh...  ...            0\n",
              "1  What is the story of Kohinoor (Koh-i-Noor) Dia...  ...            0\n",
              "2  How can I increase the speed of my internet co...  ...            0\n",
              "3  Why am I mentally very lonely? How can I solve...  ...            0\n",
              "4  Which one dissolve in water quikly sugar, salt...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1emdowWaLfk",
        "outputId": "b056f104-b108-4ae4-bc64-4525854043d3"
      },
      "source": [
        "print(f'Length of dataset \\n{len(df)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of dataset \n",
            "404290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_jNhMI8akfE"
      },
      "source": [
        "Let's view label distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm8KosQ7ag7b",
        "outputId": "ddbdec4f-575a-4ec1-b8dd-670cc8c4678f"
      },
      "source": [
        "print(f\"Number of duplicate questions: {df['is_duplicate'].value_counts()[0]}\")\n",
        "print(f\"Number of non-duplicate questions: {df['is_duplicate'].value_counts()[1]}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of duplicate questions: 255027\n",
            "Number of non-duplicate questions: 149263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwbv4AZfdhfG",
        "outputId": "20212e11-3619-4d82-ccdd-727dc0682432"
      },
      "source": [
        "print(f'The duplicate questions are {df.is_duplicate.value_counts()[0]/len(df)*100}% of the entire dataset')\n",
        "print(f'The non-duplicate questions are {df.is_duplicate.value_counts()[1]/len(df)*100}% of the entire dataset')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The duplicate questions are 63.08021469737069% of the entire dataset\n",
            "The non-duplicate questions are 36.9197853026293% of the entire dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA41KsECmIq4"
      },
      "source": [
        "Next we will do some preprocessing ,we will remove all non duplicate entries and unwanted columns from our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "2ef_Hj8QbuD9",
        "outputId": "21b15d35-d47e-40c2-b2df-54ec51412184"
      },
      "source": [
        "\n",
        "final_df=df.loc[df['is_duplicate']==1].reset_index(drop=True)\n",
        "final_df=final_df.iloc[:,:2]\n",
        "final_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>How can I see all my Youtube comments?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>How can you make physics easy to learn?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>What was your first sexual experience?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149258</th>\n",
              "      <td>What are some outfit ideas to wear to a frat p...</td>\n",
              "      <td>What are some outfit ideas wear to a frat them...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149259</th>\n",
              "      <td>Why is Manaphy childish in Pokémon Ranger and ...</td>\n",
              "      <td>Why is Manaphy annoying in Pokemon ranger and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149260</th>\n",
              "      <td>How does a long distance relationship work?</td>\n",
              "      <td>How are long distance relationships maintained?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149261</th>\n",
              "      <td>What does Jainism say about homosexuality?</td>\n",
              "      <td>What does Jainism say about Gays and Homosexua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149262</th>\n",
              "      <td>Do you believe there is life after death?</td>\n",
              "      <td>Is it true that there is life after death?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question1                                          question2\n",
              "0       Astrology: I am a Capricorn Sun Cap moon and c...  I'm a triple Capricorn (Sun, Moon and ascendan...\n",
              "1                          How can I be a good geologist?          What should I do to be a great geologist?\n",
              "2             How do I read and find my YouTube comments?             How can I see all my Youtube comments?\n",
              "3                    What can make Physics easy to learn?            How can you make physics easy to learn?\n",
              "4             What was your first sexual experience like?             What was your first sexual experience?\n",
              "...                                                   ...                                                ...\n",
              "149258  What are some outfit ideas to wear to a frat p...  What are some outfit ideas wear to a frat them...\n",
              "149259  Why is Manaphy childish in Pokémon Ranger and ...  Why is Manaphy annoying in Pokemon ranger and ...\n",
              "149260        How does a long distance relationship work?    How are long distance relationships maintained?\n",
              "149261         What does Jainism say about homosexuality?  What does Jainism say about Gays and Homosexua...\n",
              "149262          Do you believe there is life after death?         Is it true that there is life after death?\n",
              "\n",
              "[149263 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zt9sLE-mOvh"
      },
      "source": [
        "Now split dataset into train and test for modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyifaw8oNgLo"
      },
      "source": [
        "\n",
        "(df_train, df_test) = train_test_split(final_df, test_size=0.3, random_state=random.seed(SEED))\n",
        "\n",
        "assert len(df_train) + len(df_test) == len(final_df)\n",
        "df_train=df_train.reset_index(drop=True)\n",
        "df_test=df_test.reset_index(drop=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHDMymtgmUkW"
      },
      "source": [
        "Let's view length of train and test dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOxw1cFKNtqU",
        "outputId": "ff99312f-ca73-4dee-d0a6-d1fda3c60a84"
      },
      "source": [
        "len(df_train),len(df_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104484, 44779)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv9-DpWwmZMK"
      },
      "source": [
        "Load spacy model for tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf6_LgOXWqNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ca6fe8-32e8-4063-8b66-a0f5b60dc579"
      },
      "source": [
        "!pip install spacy --upgrade --quite"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: --quite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGS-Zzs2Aglb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3235dfc-5e2e-4177-d2d9-6797c3dcb4e2"
      },
      "source": [
        "%%bash\n",
        "\n",
        "python -m spacy download en --quite\n",
        "# python -m spacy download de"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  /usr/bin/python3 -m pip install [options] <requirement specifier> [package-index-options] ...\n",
            "  /usr/bin/python3 -m pip install [options] -r <requirements file> [package-index-options] ...\n",
            "  /usr/bin/python3 -m pip install [options] [-e] <vcs project url> ...\n",
            "  /usr/bin/python3 -m pip install [options] [-e] <local project path> ...\n",
            "  /usr/bin/python3 -m pip install [options] <archive url/path> ...\n",
            "\n",
            "no such option: --quite\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKK9oA7OArZK"
      },
      "source": [
        "# spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8cCeVtGmfUC"
      },
      "source": [
        "We create the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPubajj7A0pY"
      },
      "source": [
        "# def tokenize_de(text):\n",
        "#     \"\"\"\n",
        "#     Tokenizes German text from a string into a list of strings (tokens) and reverses it\n",
        "#     \"\"\"\n",
        "#     return [tok.text for tok in spacy_en.tokenizer(text)][::-1]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI2oFgyemlbw"
      },
      "source": [
        "Here our source (SRC - Input) is question 1 and target (TRG - Output) is question 2. We also add 2 extra tokens \"start of sequence\" and \"end of sequence\" for effective model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztK5PjShBN_M"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkuniACPmzHZ"
      },
      "source": [
        "Define fields to decide how we process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR61PPo7NJOo"
      },
      "source": [
        "fields=[('question1',SRC),('question2',TRG)]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7Mb5bnPlOx--",
        "outputId": "8ccaad3f-40de-444b-c4f7-5d5e3687b820"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is scope for international students who w...</td>\n",
              "      <td>What is the scope for mechanical engineers for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is shadow banking? Can you explain it in ...</td>\n",
              "      <td>What is shadow banking? Can anyone explain it ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the difference between Jainism and Bud...</td>\n",
              "      <td>What are the differences between Jainism and B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the best programming blog?</td>\n",
              "      <td>What is the best programming blogs?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are some mind blowing Magic science trick...</td>\n",
              "      <td>What are some mind-blowing science magic trick...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104479</th>\n",
              "      <td>What is the meaning of Sandeep?</td>\n",
              "      <td>What is the meaning of the name Sandeep?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104480</th>\n",
              "      <td>How do you delete pictures on Instagram at once?</td>\n",
              "      <td>How do you delete all of your Instagram photos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104481</th>\n",
              "      <td>What is A brand strategist?</td>\n",
              "      <td>What does a brand strategist do?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104482</th>\n",
              "      <td>How should I start to learn c language?</td>\n",
              "      <td>How can I study c language?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104483</th>\n",
              "      <td>How can I slim down my face?</td>\n",
              "      <td>My face is fat. How do I slim down my moon face?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104484 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question1                                          question2\n",
              "0       What is scope for international students who w...  What is the scope for mechanical engineers for...\n",
              "1       What is shadow banking? Can you explain it in ...  What is shadow banking? Can anyone explain it ...\n",
              "2       What is the difference between Jainism and Bud...  What are the differences between Jainism and B...\n",
              "3                      What is the best programming blog?                What is the best programming blogs?\n",
              "4       What are some mind blowing Magic science trick...  What are some mind-blowing science magic trick...\n",
              "...                                                   ...                                                ...\n",
              "104479                    What is the meaning of Sandeep?           What is the meaning of the name Sandeep?\n",
              "104480   How do you delete pictures on Instagram at once?  How do you delete all of your Instagram photos...\n",
              "104481                        What is A brand strategist?                   What does a brand strategist do?\n",
              "104482            How should I start to learn c language?                        How can I study c language?\n",
              "104483                       How can I slim down my face?   My face is fat. How do I slim down my moon face?\n",
              "\n",
              "[104484 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaUuGfWBm2cQ"
      },
      "source": [
        "Now we create train and test dataset from list of rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83hU-jxyOy1X"
      },
      "source": [
        "example_train=[data.Example.fromlist([df_train.question1[i],df_train.question2[i]],fields) for i in range (df_train.shape[0])]\n",
        "example_test=[data.Example.fromlist([df_test.question1[i],df_test.question2[i]],fields) for i in range (df_test.shape[0])]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jEQDQMtP9Lx"
      },
      "source": [
        "train_data = torchtext.legacy.data.Dataset(example_train, fields)\n",
        "test_data= torchtext.legacy.data.Dataset(example_test,fields)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3cCTrkoB7fu",
        "outputId": "43dc3bd3-2312-49d0-da80-6bbc71dbb5ae"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 104484\n",
            "Number of testing examples: 44779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkcjHbbuQP5V"
      },
      "source": [
        "\n",
        "Let's look at one of the examples in the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN6IJggTCBH6",
        "outputId": "60642726-945d-4103-c5f9-231fe117e194"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'question1': ['what', 'is', 'scope', 'for', 'international', 'students', 'who', 'will', 'study', 'ms', 'in', 'usa', 'in', 'mechanical', 'streams', '?'], 'question2': ['what', 'is', 'the', 'scope', 'for', 'mechanical', 'engineers', 'for', 'a', 'master', \"'s\", 'in', 'the', 'usa', 'with', 'good', 'pay', 'after', 'an', 'ms', '?']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgrO7JGFm8ok"
      },
      "source": [
        "Build vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY3qVJbpK_2L"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy0xQVgdLBkm",
        "outputId": "8ea1144a-d316-4031-f3f1-1f9d95cf532e"
      },
      "source": [
        "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (en) vocabulary: 14519\n",
            "Unique tokens in target (en) vocabulary: 14505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX1Md2W0nAZR"
      },
      "source": [
        "Define device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I_59ly4LC4T"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8TG7XHWnEvB"
      },
      "source": [
        "Create iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0GNSQSCLEOB"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data,  test_data), \n",
        "    batch_size = BATCH_SIZE,sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.question1),\n",
        "    device = device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_sCxxi4nPsQ"
      },
      "source": [
        "#  **Build Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d4O3IdJnVZA"
      },
      "source": [
        " ## Encoder\n",
        " First, the encoder, a 2 layer `LSTM`.\n",
        "\n",
        "For a multi-layer LSTM, the input sentence, $X$, after being embedded goes into the first (bottom) layer of the LSTM.Along with input sequence , LSTM take in hidden state and cell state from previous time step and return new hidden state and cell state at each time step.Initial hidden state and cell state will be initialized to tensor of all zeros.Only hidden state from the first layer is passed as input to the second layer, and not the cell state.We will also output a context vector per layer, $z^l$.Our context vector will be both the final hidden state and the final cell state, i.e. $z^l = (h_T^l, c_T^l)$.\n",
        "\n",
        "Thus, representing each layer with a superscript, the hidden states in each layer are given by:\n",
        "\n",
        "$$\\begin{align*}\n",
        "(h_t^1, c_t^1) = \\text{EncoderLSTM}^1(e(x_t), (h_{t-1}^1, c_{t-1}^1))\\\\\n",
        "(h_t^2, c_t^2) = \\text{EncoderLSTM}^2(h_t^1, (h_{t-1}^2, c_{t-1}^2))\n",
        "\\end{align*}$$\n",
        "We create this in code by making an `Encoder` module, which inherit from `torch.nn.Module` and use the `super().__init__()` as some boilerplate code. The encoder takes the following arguments:\n",
        "\n",
        "*  `input_dim` is the size/dimensionality of the one-hot vectors that will be input to the encoder. This is equal to the input (source) vocabulary size.\n",
        "\n",
        "*  `emb_dim` is the dimensionality of the embedding layer. This layer converts the one-hot vectors into dense vectors with emb_dim dimensions.\n",
        "*   `hid_dim` is the dimensionality of the hidden and cell states.\n",
        "*   `n_layers` is the number of layers in the LSTM.\n",
        "* `dropout` is the amount of dropout to use. This is a regularization parameter to prevent overfitting.\n",
        "\n",
        "\n",
        "In the `forward` method, we pass in the source sentence, $X$, which is converted into dense vectors using the embedding layer, and then dropout is applied. These embeddings are then passed into the LSTM. As we pass a whole sequence to the LSTM, it will automatically do the recurrent calculation of the hidden states over the whole sequence.We do not pass an initial hidden or cell state to the LSTM. This is because, if no hidden/cell state is passed to the LSTM, it will automatically create an initial hidden/cell state as a tensor of all zeros.\n",
        "\n",
        "The `LSTM` returns: `outputs` (the top-layer hidden state for each time-step), hidden (the final hidden state for each layer, $h_T$, stacked on top of each other) and `cell` (the final cell state for each layer, $c_T$, stacked on top of each other).\n",
        "\n",
        "As we only need the final hidden and cell states (to make our context vector), `forward` only returns hidden and cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddiTgU8hLFj1"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        \n",
        "        # Number of layers in the lstm\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        \n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "\n",
        "        # Regularization parameter\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "    def forward(self, src):\n",
        "        # print(f'En-shape of src{src.shape}')#[8, 128]\n",
        " \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # print(f'En-shape of embedded{embedded.shape}')#[8, 128, 256]\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        # print(f'En-shape of outputs{outputs.shape}')#[8, 128, 512]\n",
        "        # print(f'En-shape of hidden{hidden.shape}')#[2, 128, 512]\n",
        "\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asYdIoK_n9qA"
      },
      "source": [
        "### Decoder \n",
        "Next, we'll build our `decoder`, which will also be a 2-layer `LSTM`.\n",
        "\n",
        "The Decoder class does a single step of decoding, i.e. it ouputs single token per time-step. The first layer will receive a hidden and cell state from the previous time-step, $(s_{t-1}^1, c_{t-1}^1)$, and feeds it through the `LSTM` with the current embedded token, $y_t$, to produce a new hidden and cell state, $(s_t^1, c_t^1)$. The subsequent layers will use the hidden state from the layer below, $s_t^{l-1}$, and the previous hidden and cell states from their layer, $(s_{t-1}^l, c_{t-1}^l)$. This provides equations very similar to those in the encoder.\n",
        "\n",
        "$$\\begin{align*}\n",
        "(s_t^1, c_t^1) = \\text{DecoderLSTM}^1(d(y_t), (s_{t-1}^1, c_{t-1}^1))\\\\\n",
        "(s_t^2, c_t^2) = \\text{DecoderLSTM}^2(s_t^1, (s_{t-1}^2, c_{t-1}^2))\n",
        "\\end{align*}$$\n",
        "Remember that the initial hidden and cell states to our decoder are our context vectors, which are the final hidden and cell states of our encoder from the same layer, i.e. $(s_0^l,c_0^l)=z^l=(h_T^l,c_T^l)$.\n",
        "\n",
        "We then pass the hidden state from the top layer of the RNN, $s_t^L$, through a linear layer, $f$, to make a prediction of what the next token in the target (output) sequence should be, $\\hat{y}_{t+1}$.\n",
        "\n",
        "$$\\hat{y}_{t+1} = f(s_t^L)$$\n",
        "The arguments and initialization are similar to the Encoder class, except we now have an output_dim which is the size of the vocabulary for the output/target. There is also the addition of the Linear layer, used to make the predictions from the top layer hidden state.\n",
        "\n",
        "Within the forward method, we accept a batch of input tokens, previous hidden states and previous cell states. As we are only decoding one token at a time, the input tokens will always have a sequence length of 1. We unsqueeze the input tokens to add a sentence length dimension of 1. Then, similar to the encoder, we pass through an embedding layer and apply dropout. This batch of embedded tokens is then passed into the RNN with the previous hidden and cell states. This produces an output (hidden state from the top layer of the RNN), a new hidden state (one for each layer, stacked on top of each other) and a new cell state (also one per layer, stacked on top of each other). We then pass the output (after getting rid of the sentence length dimension) through the linear layer to receive our prediction. We then return the prediction, the new hidden state and the new cell state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKKhHPD2LHX1"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        \n",
        "        # Number of layers in the lstm\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        # Regularization parameter\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    # Shape of input [batch_size]  \n",
        "    def forward(self, input, hidden, cell):\n",
        "        # print(f'De-shape of input{input.shape}')#[128]\n",
        "\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        # print(f'De-shape of input{input.shape}')#[1, 128]\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # print(f'De-shape of embedded{embedded.shape}') #[1,128,256]   \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        # print(f'De-shape of output{output.shape}')#[1,128,512]\n",
        "        # print(f'De-shape of hidden{hidden.shape}')#[2,128,512]\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "  \n",
        "        prediction = self.fc_out(output.squeeze(0))# [128, 1271]\n",
        "        # print(f'De-shape of prediction{prediction.shape}')\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ay6PcxFoJxI"
      },
      "source": [
        "## Seq2Seq (Encoder + Decoder) \n",
        "For the final part of the implemenetation, we'll implement the `seq2seq` model. This will handle:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   receiving the input/source sentence\n",
        "*   using the encoder to produce the context vectors\n",
        "*   using the decoder to produce the predicted output/target sentence\n",
        "\n",
        "\n",
        "\n",
        "The `Seq2Seq` model takes in an Encoder, Decoder, and a device (used to place tensors on the GPU, if it exists).\n",
        "\n",
        "\n",
        "\n",
        "Our `forward` method takes the source sentence, target sentence and a teacher-forcing ratio. The teacher forcing ratio is used when training our model. When decoding, at each time-step we will predict what the next token in the target sequence will be from the previous tokens decoded, \n",
        "$\\hat{y}_{t+1}=f(s_t^L)$. With probability equal to the teaching forcing ratio (`teacher_forcing_ratio`) we will use the actual ground-truth next token in the sequence as the input to the decoder during the next time-step. However, with probability 1 - `teacher_forcing_ratio`, we will use the token that the model predicted as the next input to the model, even if it doesn't match the actual next token in the sequence.\n",
        "\n",
        "The first thing we do in the forward method is to create an outputs tensor that will store all of our predictions, $\\hat{Y}$.\n",
        "\n",
        "\n",
        "We then feed the input/source sentence, src, into the encoder and receive out final hidden and cell states.\n",
        "\n",
        "\n",
        "The first input to the decoder is the start of sequence (`<sos>`) token. As our trg tensor already has the `<sos>` token appended we get our $y_1$ by slicing into it. We know how long our target sentences should be (max_len), so we loop that many times. The last token input into the decoder is the one before the <eos> token - the\n",
        "\n",
        "During each iteration of the loop, we:\n",
        "\n",
        "pass the input, previous hidden and previous cell states ($y_t, s_{t-1}, c_{t-1}$) into the decoder\n",
        "receive a prediction, next hidden state and next cell state ($\\hat{y}_{t+1}, s_{t}, c_{t}$) from the decoder\n",
        "place our prediction, $\\hat{y}_{t+1}$/output in our tensor of predictions, $\\hat{Y}$/outputs\n",
        "decide if we are going to \"teacher force\" or not\n",
        "if we do, the next input is the ground-truth next token in the sequence, $y_{t+1}$/trg[t]\n",
        "if we don't, the next input is the predicted next token in the sequence, $\\hat{y}_{t+1}$/top1, which we get by doing an argmax over the output tensor\n",
        "Once we've made all of our predictions, we return our tensor full of predictions, $\\hat{Y}$/outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIf8EPxVLJhx"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh9tddmXobG4"
      },
      "source": [
        "## **Training Model**\n",
        "\n",
        "We define the encoder, decoder and then our Seq2Seq model, which we place on the device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i0_86JVLL-9"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIQfknQDoeDI"
      },
      "source": [
        "\n",
        "Next step is initializing the weights of our model.We initialize all weights from a uniform distribution between -0.08 and +0.08. For each module we loop through all of the parameters and sample them from a uniform distribution with `nn.init.uniform`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBhX5dKuLNar",
        "outputId": "36097243-670f-4fdb-d0e8-53e645766d78"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(14519, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(14505, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=14505, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulX_DOGSogua"
      },
      "source": [
        "\n",
        "We also define a function that will calculate the number of trainable parameters in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSdevJJNLPOt",
        "outputId": "cbe693be-9dbe-4bf0-af5a-f7afbd941875"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 22,227,625 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3mRz-esoj2W"
      },
      "source": [
        "\n",
        "We define our optimizer, which we use to update our parameters in the training loop. Here, we'll use Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-CvhZwYLQoT"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb7Lk2aqon_x"
      },
      "source": [
        "Next, we define our loss function as CrossEntropyLoss function. Our loss function calculates the average loss per token, however by passing the index of the <pad> token as the ignore_index argument we ignore the loss whenever the target token is a padding token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO11j3WELR5P"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIwz_G6_oqsJ"
      },
      "source": [
        "\n",
        "Next, we'll define our training loop.\n",
        "\n",
        "First, we'll set the model into \"training mode\" with model and then iterate through our data iterator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-HReR1sLS8w"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        question1 = batch.question1\n",
        "        question2 = batch.question2\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(question1, question2)\n",
        "        \n",
        "        #question2 = [question2 len, batch size]\n",
        "        #output = [question2 len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        question2 = question2[1:].view(-1)\n",
        "        \n",
        "        #question2 = [(question2 len - 1) * batch size]\n",
        "        #output = [(question2 len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, question2)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKoFQxXxotlA"
      },
      "source": [
        "Next, we'll define our evaluation loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfm7iiOmLUhv"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            question1 = batch.question1\n",
        "            question2 = batch.question2\n",
        "\n",
        "            output = model(question1, question2, 0) #turn off teacher forcing\n",
        "\n",
        "            #question2 = [question2 len, batch size]\n",
        "            #output = [question2 len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            question2 = question2[1:].view(-1)\n",
        "\n",
        "            #question2 = [(question2 len - 1) * batch size]\n",
        "            #output = [(question2 len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, question2)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xEjQ1ooowkI"
      },
      "source": [
        "\n",
        "Next, we'll create a function that we'll use to tell us how long an epoch takes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXrLres2LWHg"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRvpjHHEozHo"
      },
      "source": [
        "We can finally start training our model!\n",
        "\n",
        "At each epoch, we'll be checking if our model has achieved the best validation loss so far. If it has, we'll update our best validation loss and save the parameters of our model . Then, when we come to test our model, we'll use the saved parameters used to achieve the best validation loss.\n",
        "\n",
        "We'll be printing out both the loss and the perplexity at each epoch. It is easier to see a change in perplexity than a change in loss as the numbers are much bigger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGdzElxhLXKm",
        "outputId": "d785e788-3d24-492d-a850-794e8f1e1925"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "train_los=[]\n",
        "test_los=[]\n",
        "best_test_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    train_los.append(train_loss)\n",
        "    test_loss = evaluate(model, test_iterator, criterion)\n",
        "    test_los.append(test_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        torch.save(model.state_dict(), 'saved-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Test. Loss: {test_loss:.3f} |  Test. PPL: {math.exp(test_loss):7.3f}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 4m 15s\n",
            "\tTrain Loss: 2.078 | Train PPL:   7.990\n",
            "\t Test. Loss: 3.579 |  Test. PPL:  35.835\n",
            "Epoch: 02 | Time: 4m 17s\n",
            "\tTrain Loss: 2.008 | Train PPL:   7.446\n",
            "\t Test. Loss: 3.590 |  Test. PPL:  36.251\n",
            "Epoch: 03 | Time: 4m 16s\n",
            "\tTrain Loss: 1.949 | Train PPL:   7.019\n",
            "\t Test. Loss: 3.590 |  Test. PPL:  36.238\n",
            "Epoch: 04 | Time: 4m 16s\n",
            "\tTrain Loss: 1.889 | Train PPL:   6.614\n",
            "\t Test. Loss: 3.642 |  Test. PPL:  38.156\n",
            "Epoch: 05 | Time: 4m 15s\n",
            "\tTrain Loss: 1.850 | Train PPL:   6.358\n",
            "\t Test. Loss: 3.683 |  Test. PPL:  39.748\n",
            "Epoch: 06 | Time: 4m 16s\n",
            "\tTrain Loss: 1.798 | Train PPL:   6.037\n",
            "\t Test. Loss: 3.729 |  Test. PPL:  41.646\n",
            "Epoch: 07 | Time: 4m 19s\n",
            "\tTrain Loss: 1.774 | Train PPL:   5.895\n",
            "\t Test. Loss: 3.724 |  Test. PPL:  41.418\n",
            "Epoch: 08 | Time: 4m 18s\n",
            "\tTrain Loss: 1.724 | Train PPL:   5.605\n",
            "\t Test. Loss: 3.753 |  Test. PPL:  42.634\n",
            "Epoch: 09 | Time: 4m 17s\n",
            "\tTrain Loss: 1.687 | Train PPL:   5.402\n",
            "\t Test. Loss: 3.756 |  Test. PPL:  42.783\n",
            "Epoch: 10 | Time: 4m 17s\n",
            "\tTrain Loss: 1.669 | Train PPL:   5.306\n",
            "\t Test. Loss: 3.778 |  Test. PPL:  43.744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7nkE-aio2yR"
      },
      "source": [
        "Let's view train and test loss of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjUCB1yYMfIa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "ef09e821-749d-4a73-8841-df534b9a5efc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "plt.figure()\n",
        "plt.plot(train_los, color = 'magenta')\n",
        "plt.plot(test_los, color = '#606060')\n",
        "plt.title('Train and test Loss')\n",
        "plt.legend(['train_loss', 'test_loss'], loc = 'upper right')\n",
        "plt.grid(axis = 'y', c = 'black', alpha = 0.2)\n",
        "plt.grid(axis = 'x', c = 'black', alpha = 0.2)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZZ64YDFpCYT"
      },
      "source": [
        "## **Inference**\n",
        "\n",
        "\n",
        "Now, we'll grab some answers to questions from our dataset and see how well our model did."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndFjPRpAo_Df"
      },
      "source": [
        "def predict_duplicate(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en_core_web_sm')\n",
        "        #('en_core_web_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    # src_len = torch.LongTensor([len(src_indexes)])\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        hidden,cell = model.encoder(src_tensor)\n",
        "\n",
        "        \n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    # attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "            # output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "\n",
        "            \n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXKK5UWRpFmR"
      },
      "source": [
        "Let's see how model predicts question from training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6YCskPapTft",
        "outputId": "fa838aea-68e2-4721-a185-91d62846b0be"
      },
      "source": [
        "example_idx = 20\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['question1']\n",
        "trg = vars(train_data.examples[example_idx])['question2']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['what', 'does', 'it', 'feel', 'like', 'to', 'rob', 'a', 'bank', '?']\n",
            "trg = ['what', 'is', 'it', 'like', 'to', 'rob', 'a', 'bank', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSKU3EiDpXFV",
        "outputId": "7e4b363a-7f86-481d-e57d-1e3889b80c50"
      },
      "source": [
        "pred_duplicate= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {pred_duplicate}')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['what', 'is', 'it', 'like', 'to', 'rob', 'a', 'bank', '?', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD4-7nwTpUp2"
      },
      "source": [
        "Let's predict some answers from test set too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7KZD-RvpZms",
        "outputId": "c237da96-e291-448d-9fe2-c62b6b8d3ab2"
      },
      "source": [
        "example_idx = 6\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['question1']\n",
        "trg = vars(test_data.examples[example_idx])['question2']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "pred_duplicate= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {pred_duplicate}')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['what', 'are', 'things', 'which', 'i', 'can', 'export', 'from', 'india', '?']\n",
            "trg = ['what', 'is', 'the', 'best', 'thing', 'to', 'export', 'from', 'india', '?']\n",
            "predicted trg = ['what', 'are', 'some', 'ideas', 'to', 'to', 'buy', 'from', 'india', '?', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvHP6qtqwofZ",
        "outputId": "0d7e9962-3e9b-4f08-be71-c78c83103d50"
      },
      "source": [
        "example_idx = 50\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['question1']\n",
        "trg = vars(test_data.examples[example_idx])['question2']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "pred_duplicate= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {pred_duplicate}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['why', 'are', 'there', 'still', 'poor', 'people', 'in', 'the', 'world', '?']\n",
            "trg = ['why', 'do', 'you', 'think', 'there', 'are', 'so', 'many', 'poor', 'people', 'in', 'the', 'world', '?', 'how', 'did', 'it', 'get', 'that', 'way', '?', 'were', 'there', 'always', 'poor', 'people', '?']\n",
            "predicted trg = ['why', 'are', 'there', 'so', 'many', 'people', 'in', 'the', 'world', '?', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-Mr4dHewq4z",
        "outputId": "1f5d5c4b-d6e1-46a1-8587-23648c488470"
      },
      "source": [
        "example_idx = 10\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['question1']\n",
        "trg = vars(test_data.examples[example_idx])['question2']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "pred_duplicate= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {pred_duplicate}')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['how', 'can', 'i', 'speak', 'english', 'fluently', 'and', 'fast', '?']\n",
            "trg = ['how', 'do', 'i', 'speak', 'english', 'like', 'celebrities', '?']\n",
            "predicted trg = ['how', 'can', 'i', 'speak', 'fluent', 'english', 'with', 'confidence', '?', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYOqqJnnws4i",
        "outputId": "17799494-db28-4332-b2bf-1e98f30da94d"
      },
      "source": [
        "example_idx = 5\n",
        "\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['question1']\n",
        "trg = vars(test_data.examples[example_idx])['question2']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "pred_duplicate= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {pred_duplicate}')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['who', 'is', 'the', 'most', 'badass', 'footballer', 'ever', '?']\n",
            "trg = ['who', 'is', 'the', 'most', 'badass', 'footballer', 'ever', '?', 'why', '?']\n",
            "predicted trg = ['who', 'is', 'the', 'most', 'overrated', 'footballer', '?', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "071s6Hn2C05C",
        "outputId": "29ed8abe-6857-4125-eb1d-8ccbfbf5e557"
      },
      "source": [
        "example_idx = 25\n",
        "\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['question1']\n",
        "trg = vars(test_data.examples[example_idx])['question2']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "pred_duplicate= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {pred_duplicate}')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['which', 'laptop', 'is', 'better', 'till', '60000', '?']\n",
            "trg = ['which', 'is', 'the', 'best', 'gaming', 'laptop', 'under', 'rs', '60000', '?']\n",
            "predicted trg = ['what', 'is', 'the', 'best', 'laptop', 'under', 'rs.60000', 'in', 'india', '?', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybASbWedC2H2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}